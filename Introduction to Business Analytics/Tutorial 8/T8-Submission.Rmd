---
title: 'Tutorial 8: Data Mining Basics'
author: "Ali"
date: "Due by October 24, 9:00 AM"
output: html_document
---

## Preparation
```{r load-libraries, echo=TRUE, warning = FALSE, message = FALSE}
# load required packages
library(dplyr)
library(tidyr)
library(car) # for linearHypothesis()
library(ggplot2) # optional. we expect you to know base graphics, but allow ggplot if you find it easier
library(psych) # for pairs.panels()
library(factoextra) # for fviz_cluster()
library(wooldridge)
```

## Part Two: Assignment Submission 

### Question 2 (Total 20 points)

- Dataset required: `gpa2` (wooldridge)

The dataset for this question is available at: https://rdrr.io/cran/wooldridge/man/gpa2.html, a public available dataset about class performance for the first fall semester in college, containing 4137 observations on 12 variables. Again, you need to install and load package `wooldridge` to conveniently load the data into your R workplace. 

```{r q2-dataloading, echo=TRUE}
data('gpa2')
```

Here are the variables in the dataset:

- `sat`: combined SAT score
- `tothrs`: total studying hours through fall semest
- `colgpa`: GPA after fall semester, in a 4.0 scale
- `athlete`: =1 if athlete
- `verbmath`: verbal/math SAT score
- `hsize`: size grad. class in high school, 100s
- `hsrank`: rank in grad. class in high school
- `hsperc`: high school percentile, from top
- `female`: =1 if female
- `white`: =1 if white
- `black`: =1 if black
- `hsizesq`: hsize^2

For the purpose of illustration, I crate a new variable `scholarship` (granted scholarship after the first semester) which is equal to one if student's class performance belongs to upper 20% of class comparable to his/her peers (curved) based on the GPA after the fall semester, i.e. `colgpa` is greater than 80th-quantile of `colgpa`, This would be a binary dependent variable we shall use in prediction and classification.

In this question, we will be interested in using the independent variables (student's academic performance in SAT and high school) to classify and predict whether student will be granted scholarship or not after their first semester. 

Here is a brief data description for all independent variables (using the `pairs.panels()` function from the `psych` package)

```{r q2-read-in-dataset, echo=TRUE, fig.width=10}
# create a binary variable 'pass',
gpa2$scholarship = ifelse(gpa2$colgpa > quantile(gpa2$colgpa, 0.8), 1, 0)
# Selecting out the independent variables "X" included in our analysis.
gpa2X <- gpa2 %>% select(-c("colgpa", "scholarship"))
psych::pairs.panels(gpa2X, lm=TRUE)
```

Q2(a) Using the entire data set `gpa2`, let's first start with the  "kitchen sink" regression model `colgpa ~ . - colgpa - scholarship`, i.e. we include all independent variables on the RHS of the regression.

 - using `linearHypothesis()` to jointly test if first semester's GPA is affected by the size of graduating class in high school, i.e. `hsize = hsizesq = 0`. Draw your conclusion for the test; (2 points)
 - run an automated backward model selection using `step()` function and interpret the coefficient of `tothrs`. Do you expect the sign of the coefficient before `tothrs`? (3 points)
 - run an automated forward model selection and report the selected model. Does the forward model selection agree with the backward selection? (2 points)

```{r q2a, echo=TRUE}
#i
fit_unrestricted <- lm(colgpa ~ . -colgpa - scholarship, gpa2)
linearHypothesis(fit_unrestricted, c("hsize = 0", "hsizesq = 0"))

#ii
step(fit_unrestricted, direction = 'backward')

#iii
fit_intercept <-  lm(`colgpa` ~ 1 -colgpa - scholarship, gpa2)
step(fit_intercept, scope = ~ sat + tothrs + athlete + verbmath + hsize + hsrank + hsperc + female + white + black + hsizesq, direction = 'forward')
```

<p style="color:darkred">
**i)** <br>
Conclusion for linear hypothesis test <br>
H0: The second unrestricted model is not significantly better than the first restricted model in terms of explanatory power for Y (colgpa). <br>
H1: The second unrestricted model is significantly better than the first restricted model in terms of explanatory power for Y (colgpa). <br>
Since F-test p-value = 0.1365 > 0.05, there is insufficient evidence to reject the null hypothesis and conclude that unrestricted model is not significantly better than restricted model (without hsize and hsizesq) in terms of its explanatory power. Hence it may be concluded that hsize and hsizesq does not necessarily improve the explanatory power of the model to predict our dependent var wage colgpa. <br>

**ii)** <br>
Automated backward model selection <br>
The coefficient of tothrs is 0.001730. On average, as one unit increase in tothrs, colgpa increases by 0.001730, when all other independent variables are held constant. step(backward) function in each step excludes the top listed predictor which is ranked by AIC with RSS. Since the final model of the backward stepwise selection model only presents variables that are statistically significant, tothrs is a statistically significant predictor of GPA after fall semester colgpa. The coefficient is expected to be positive since the total number of hours put into studying has a direct relationship to one’s GPA on average. <br>

**iii)** <br>
Automated forward model selection <br>
Forward stepwise selection starts with an intercept-only model, and proceeds to conduct F-tests for all potential predictors and add the one with largest F-statistics; repeats with the updated model until the endpoint. <br>
The selected model: colgpa = 1.202323 + -0.009840 hsperc + 0.001503 sat + 0.145413 female + 0.001730 tothrs -0.001434 hsrank + 0.217561 athlete + 0.001540 hsizesq. Hence, the forward model selection agrees with the backward selection since they reach the same conclusion. Both have AIC = -5005.6 in their final step.
</p>


Q2(b) From the correlation matrix at the very beginning, we can see that some of the independent variables are correlated with each other. Let's try to summarize the data using principal component analysis (PCA). Use the `prcomp` function to conduct a PCA to summarize the information from the independent variables. (1 point)

- How many top PC's we should retain if we'd like to have our PC's represent more than 90% of variation in the data? (1 points)
- Extract the those PCs and pass them to `gpa2`. We'll be using them as predictors later. (1 point)

Hint: Note that PCA only works well with *continuous* numeric variables.

```{r q2b, echo=TRUE}
pca_gpa2 <- prcomp(formula = ~ . -colgpa -athlete -female -white -black -scholarship, data = gpa2, center = TRUE, scale = TRUE)
summary(pca_gpa2)

gpa2$pc1 = pca_gpa2$x[,"PC1"]
gpa2$pc2 = pca_gpa2$x[,"PC2"]
gpa2$pc3 = pca_gpa2$x[,"PC3"]
gpa2$pc4 = pca_gpa2$x[,"PC4"]
gpa2$pc5 = pca_gpa2$x[,"PC5"]
```

<p style="color:darkred">
The top 5 PCs should be retained in order to represent more than 90% of variation in the data.
</p>

Q2(c) On the entire data `gpa2`, use a logistic classifier for `scholarship` with the top the five principal components. Which coefficients are statistically significant? (2 points)

Using your trained logit classifier with those five PCs, call `predict(<glm_object>, type='response')` to ask the model to predict the probability of getting a scholarship after the first semester in college. Let's make our rule to define the *predicted value* of `scholarship`: one if the predicted probability is >=0.50; zero if <0.50. Pass the binary predictions to a variable named `pred_scholarship` in `gpa2`. How many "Yes" (positives) and "No" (negatives) predictions did the model make? (3 points)

```{r q2c, echo=TRUE}
fit_scholarship <-  glm(scholarship ~ pc1 + pc2 + pc3 + pc4 + pc5, family = binomial, data = gpa2, control = list(maxit = 50))
summary(fit_scholarship)

predprob_scholarship <- predict(fit_scholarship, type = 'response')
gpa2$pred_scholarship <- ifelse(predprob_scholarship>= 0.5, 1, 0)
gpa2 %>% count(pred_scholarship)
```

<p style="color:darkred">
The coefficients of pc1, pc2, pc3 and pc4 are all statistically significant since their p-values: 2e-16,2e-16, 0.00119 and 3.07e-06 are all < 0.05. Hence there is sufficient evidence to reject the null hypothesis that the slope parameter for each variable is equal to zero. Therefore, accept the alternative hypothesis that respective coefficients pc1, pc2, pc3 and pc4 is statistically different from 0. The model made 3761 “Yes” predictions and 376 “No” predictions.
</p>



Q2(d) Finally, let's manually construct a classification matrix using `table()` function in base R rather than `caret::confusionMatrix()` to evaluate our logistic classifier.

Use `table(x1, x2)` with both your model's "Scholarship" predictions and the actual observed `scholarship` values (ignoring that we actually created `scholarship` at the first place). I recommend using the same convention in the lecture slides, where we have observed values on the columns and model prediction on the rows. *We say "granted a scholarship" as a positive event.* (4 points)

- How many True Positives are there?
- How many True Negatives are there?
- How many False Positives are there?
- How many False Negatives are there?

- What is the model's overall classification accuracy?
- What is the model's sensitivity?
- What is the model's precision?
- What is the model's specificity?

Note: show the formula how you computed each quantity above.

```{r q2d, echo=TRUE}
table_scholarship <-  table(gpa2$pred_scholarship, gpa2$scholarship)
rownames(table_scholarship) <- c("Predicted:No", "Predicted:Yes")
colnames(table_scholarship) <- c("Actual:No", "Actual:Yes")
table_scholarship 

oca <- (251+3199)/(251+3199+562+125)
oca

sensitivity <- 251/(251+562)
sensitivity

precision <- 251/(251+125)
precision

specificity <- 3199/ (3199 + 125)
specificity
```

<p style="color:darkred">
There are 251 True Positives (TP), 3199 True Negatives (TN), 125 False Positives (FP) and 562 False Negatives (FN). <br>

Overall classification accuracy = (TP + TN)/ (TP + FN + FP + TN) = (251 + 3199) / (251 + 3199 + 562 + 125) = 0.834 (3s.f) <br>

Sensitivity = TP / (TP + FN) = 251 /(251 + 562) = 0.309 (3s.f) <br>

Precision = TP / (TP + FP) = 251 / (251 + 125) = 0.668 (3s.f) <br>

Specificity = TN / (FP + TN) = 3199 / (3199 + 125) = 0.962 (3s.f)
</p>

Q2(e) Successfully debug and produce an HTML for submission. (1 point)